---
title: "Anomaly detection in dynamic networks"
author: "Andreina Alamo, Zaith Moreno, Diego Useche"
subtitle: "Seminario I 2024-I"
institute: "Universidad Nacional de Colombia"
format:
  revealjs: 
    center: true
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: "logoUN3.PNG"
    #footer: Universidad Nacional de Colombia
editor: visual
# toc: true
toc-title: Contenido
progress: true
---

<!-- Empieza Zaith -->

# Introducción 

# Objetivos

# Conceptos Previos 

# Redes

![Visualización de redes (gráfos)](Red1.png){fig-align="center"}

$\bullet$ Red $\bullet$ Grafo $\bullet$ Objetos (vértices o nodos) $\bullet$ Conexiones (enlaces o aristas)$\bullet$ Interacciones (propiedades a nivel global)$\bullet$

## Ejemplos de redes{.smaller}
## Ejemplos de redes
::: {.panel-tabset}

### Estructuras cerebrales

![Estructuras cerebrales](brain.png){width="300" height="300"}

### Redes de trenes

![Redes de trenes](train.png){width="250" height="250"}

### Redes eléctricas

![Redes eléctricas](electric.png){width="250" height="250"}

### Redes Sociales

![Redes sociales](social.png){width="300" height="300"}
:::

## Redes dinámicas

![Redes dinámicas (componente temporal)](Red2.png)

## ¿Por qué es importante la detección de anomalías? {.smaller}

-   Accidentes, eventos sospechosos, actividad inusual que merece **investigación adicional**.
-   Los estudios sobre la detección de anomalías en Redes Dinámicas son **limitados**.
-   Existen estudios sobre anomalías en nodos y aristas, o en subgrafos de estructuras de interés, pero no sobre los **puntos en el tiempo** donde se producen estas anomalías.
-   Akoglu (2015) categorizó las técnicas de detección de anomalías en Redes Dinámicas en cuatro grupos: Características, Descomposición, Agrupamiento y Ventanas.

## ***oddnet***

> *Series de tiempo*: tratamiento de patrones estacionales complejos que la similaridad no alcanza a capturar

> *Análisis de redes*: Examinar las caracteristicas (Features) de las redes en el tiempo

> *Reducción de dimensionalidad*:recolectar la mayor cantidad de información de las caracteristicas en en plano


## Algoritmo ***oddnet***

![](algoritmo.PNG)

<!-- Termina Zaith -->

<!-- Empieza Andreina -->

# Anomalía en redes dinámicas {.smaller} 

Considere una secuencia de redes temporales $\left\{\mathcal{G}_t\right\}_{t=1}^T$ donde cada red es un grafo $\mathcal{G}_t=\left(\mathcal{V}_t, \mathcal{E}_t\right)$, con $\mathcal{V}_t$ denotando los vértices y $\mathcal{E}_t$ los bordes. Estamos interesados en el proceso general o a largo plazo de generación de redes. Una anomalía se define como un punto con baja probabilidad condicional

$$
\begin{aligned}
p_{t \mid t-1}=\mathcal{P}\left(\mathcal{G}_t \mid \mathcal{G}_1, \ldots, \mathcal{G}_{t-1}\right). 
\end{aligned}
$$ Es decir, un grafo $\mathcal{G}_t$ es anómalo si su probabilidad de ocurrencia es baja dada la secuencia de gráficos que lo preceden.

## Mapeo del espacio de gráficos al espacio de características

Sea $f$ una función de cálculo de características tal que $f: \mathscr{G} \rightarrow \mathbb{R}^n$, donde $\mathscr{G}$ denota el espacio de todas las redes, y sea $x_t$ la imagen de $\mathcal{G}_t$ bajo $f$. Así, $x_t$ es un vector de $n$ características correspondientes a $\mathcal{G}_t:$

$$
x_t=f\left(\mathcal{G}_t\right),
$$

donde $x_t \in \mathbb{R}^n$. Sea $\mathcal{F}$ el codominio de $f$, al cual llamaremos espacio de características.

## 

Este espacio de características $\mathcal{F}$ debe retener aspectos de la distribución del espacio de gráficos $\mathscr{G}$. Así, la probabilidad condicional definida para la detección de anomalías se puede estimar como sigue:

$$
\tilde{p}_{t \mid t-1}=\mathcal{P}\left(x_t \mid x_1, \ldots, x_{t-1}\right).
$$

donde $x_t \in \mathbb{R}^n$.

## Definición 2.1

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Acuerdo Total para un conjunto de gráficos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si

$$
p_{t \mid t-1}=\tilde{p}_{t \mid t-1} \quad \text { para todo } t \in\{1, \ldots, T\} .
$$

La Condición de Acuerdo Total es la forma más estricta de acuerdo entre los dos espacios $\mathscr{G}$ y $\mathcal{F}$. A continuación, se define una versión más flexible.

## Definición 2.2

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Acuerdo Aproximado con parámetro $\epsilon$, o se dice que es $\epsilon$-aproximada para un conjunto de gráficos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si

$$
\left|p_{t \mid t-1}-\tilde{p}_{t \mid t-1}\right| \leq \epsilon \quad \text { para todo } t \in\{1, \ldots, T\} ，
$$

donde $\epsilon>0$ y es pequeño.

## Definición 2.3

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Preservación de Anomalías con parámetro $\epsilon$, o se dice que es $\epsilon$-preservadora de anomalías para un conjunto de gráficos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si y solo si $p_{t \mid t-1} \leq \epsilon_1$ implica que existe $\epsilon_2>0$ con $\epsilon=\max \left(\epsilon_1, \epsilon_2\right)$ tal que $\tilde{p}_{t \mid t-1} \leq \epsilon_2$. Es decir,

$$
p_{t \mid t-1} \leq \epsilon_1 \Longleftrightarrow \tilde{p}_{t \mid t-1} \leq \epsilon_2
$$

donde tanto $\epsilon_1$ como $\epsilon_2$ son pequeños.

## Lema 2.1

Las condiciones de acuerdo están anidadas, es decir, Condición de Acuerdo Total $\Rightarrow$ Condición de Acuerdo Aproximado, Condición de Acuerdo Aproximado $(\epsilon / 2) \Rightarrow$ Condición de Preservación de Anomalías $(\epsilon)$.

## Ejemplo

<p align="center">

<img src="ejemplo1.png" width="1000"/>

</p>

## Características

Para cada red $\mathcal{G}_t$ se calculan 20 medidas teóricas de los grafos

1.  Distribución de triángulos:# de triángulos conectados a cada nodo
2.  Grado: \# de aristas conectado a cada nodo
3.  Densidad: \# de aristas observadas/total posibles aristas
4.  Total de aristas en $\mathcal{G}_t$
5.  Transitividad (*amigos de amigos*):Proporción de nodos cuyos nodos adyacentes también están conectados

## Características

6.  Asortatividad: Medición de la homofilia [^1] del grafo, basándose en las etiquetas de los nodos
7.  Distancia media: calcula la media de todos los caminos entre diferentes nodos
8.  Diámetro: Distancia más grande del grafo [^2]
9.  Proporción de nodos no conectados
10. Centralidad: Mide qué tan "cerca" está un nodo a otros nodos 
11. The vertex connectivity gives the minimum number of vertices/nodes that needs to be removed to make the graph not strongly connected. A graph is a strongly connected if any vertex can be reached by any other vertex.
12. The global efficiency is defined as the average inverse pairwise distances between all pairs of nodes.
13. We extract two features from the connected components in the network. From the distribution of the number of nodes in each connected component we use the $99^{\text {th }}$ quantile as our feature.
14. The number of connected components is also included.
15. Centrality is a key aspect of network analysis. Closeness centrality of a vertex measures how close that vertex is to other vertices in the graph. It is defined as the inverse of the sum of distances to all vertices. We compute the closeness centrality for all vertices and include the proportion of vertices with closeness $\geq 0.8$ in the feature vector. For this feature, we do not use the $99^{\text {th }}$ quantile because closeness centrality lies between 0 and 1 and for most graphs the $99^{\text {th }}$ quantile is equal to 1 , making it a non-informative measure.

16. Another important centrality measure is betweenness centrality. Betweenness measures how much a node connects other nodes by being a go-between. Suppose node A connects two groups of nodes, which otherwise would not be connected. In this case, node A has high betweenness centrality. It is defined as the number of shortest paths going through a node. Again, we compute the distribution for all nodes and take the $99^{\text {th }}$ quantile as our feature.
17. PageRank is another measure of node importance. We compute the PageRank of all vertices and take the $99^{\text {th }}$ quantile.
18. Hub scores also compute node importance. The hub scores of the vertices are defined as the principal eigenvector of $A A^T$ where $A$ denotes the adjacency matrix. We use the principal eigenvalue corresponding to the hub scores as a feature.
19. Authority scores provide another measure of node importance. The authority scores of the vertices are the principal eigenvector of $A^T A$. We include the principal eigenvalue corresponding to the authority scores as a feature. The hub score and authority score features are identical for undirected graphs, but are different for directed graphs.
20. Cores describe group/community aspects in a graph. The $k$-core of a graph is a maximal subgraph with minimum degree at least $k$. That is, each vertex in a $k$-core has degree greater than equal to $k$. For example, if a group of friends are in a $k$-core, each person in the group knows at least $k$ other people. The coreness of a vertex is defined as $k$ if it belongs to a $k$-core, not to a $(k+1)$-core. We compute the coreness for all vertices and include the $99^{\text {th }}$ quantile.

[^1]: Nodos similares tienen a conectarse entre sí

[^2]: Distancia es la caminata más corta entre dos nodos

# Proceso de generación de red {.smaller}

El proceso que genera la red puede crear dependencias temporales dentro del espacio de características. Por ejemplo, si el número de conexiones en una red aumenta con el tiempo, una disminución repentina en el número de conexiones en un punto específico del tiempo se consideraría una anomalía. Es crucial capturar este comportamiento. Simplemente identificar anomalías en el espacio de características no nos permitiría señalar esa anomalía en particular, como se ilustra en la Figura 4.

------------------------------------------------------------------------

<p align="center">

<img src="figure_4.png" width="1000"/>

</p>

------------------------------------------------------------------------

Para modelar el comportamiento temporal, utilizamos métodos para pronósticar series de tiempo sobre las características de la red.

Sea $x_{\cdot, i}=\left\{x_{t, i}\right\}_{t=1}^T$ el conjunto de series temporales univariadas de la $i$-ésima característica.

-   Se ajustan modelos ARIMA a cada serie temporal de características $x_{\cdot, i}$ para $i \in \{1, \ldots, n\}$.

-   Si el modelo ha capturado adecuadamente la dependencia temporal, entonces $e_{t, i} \sim \mathcal{NID}\left(0, \sigma^2\right)$ y los residuos no mostrarán correlación temporal.

## Definición 2.4.

Los modelos ARIMA aproximan el proceso generador de la red con el parámetro $\delta$, si

$$
\tilde{p}_{t \mid t-1} \geq \delta \Longleftrightarrow \left\| \boldsymbol{e}_t \right\| \leq c(\delta),
$$ para valores pequeños de $\delta$. Esto asegura que los modelos ARIMA capturan los patrones generales, incluyendo la tendencia y la estacionalidad en el espacio de características, al mapear puntos de alta densidad en la distribución condicional $f\left(\mathcal{G}_t\right) \mid \mathcal{G}_1, \ldots, \mathcal{G}_{t-1}$ a residuos pequeños.

## Proposición 2.1.

Si una función $f$ satisface la Condición de Preservación de Anomalías con parámetro $\epsilon$, y si los modelos ARIMA aproximan el proceso generador de la red con parámetro $\delta$ con $\delta \geq \epsilon$, entonces un grafo anómalo $\mathcal{G}_t$ da lugar a una anomalía en el espacio de residuos de ARIMA, es decir, existe un valor pequeño $\xi$ tal que $\mathcal{P}\left(\boldsymbol{e}_t\right) \leq \xi$, donde $\xi=\xi(\delta)$ y $\boldsymbol{e}_t$ es el residuo correspondiente al grafo $\mathcal{G}_t$.

------------------------------------------------------------------------

Así, queda demostrado que los grafos anómalos quedan representados por residuales de valores grandes resultantes del ajuste del modelo ARIMA.

------------------------------------------------------------------------

<p align="center">

<img src="figure_5.png" width="1000"/>

</p>

------------------------------------------------------------------------

## Reduccion de dimensionalidad y deteccion de anomalias

Identificar anomalías en dimensiones altas supone una dificultad, dado que los puntos pueden estar muy lejos unos de otros y muchos puntos residen en regiones de baja densidad. Además, se pueden correlacionar errores de diferentes características.

**¿Como? -\>** Reduccion de dos dimensiones, dobin, ó PCA robusto.

## 

Para nuestros escenarios de red, una PCA robusta proporcionó un mejor rendimiento en comparación con dobin, posiblemente porque dobin no manejó las correlaciones tan bien como un PCA robusto

El PCA usado utiliza una estimacion robusta de la varianza dada por la desviacion absoluta mediana al cuadrado

$$ MAD(z_1,...,z_n) = 1.48med_j\|z_j - med_i(z_i)\| $$

## Deteccion de anomalias

El ultimo paso es la deteccion de anomalias en el espacio reducido a dos dimensiones, mediante el algoritmo Lookup, ingresando una matriz de datos $X$ y un valor $\alpha$, se retornan las anomalias y las probabilidades de estar por debajo de $\alpha$

El proceso general del algoritmo oddnet se puede describir con el siguiente diagrama:

<p align="center">

<img src="proceso general.png" width="1000"/>

</p>

## Resultados

### Ejercicios de simulacion

Para contrastar los resultados del algoritmo oddnet, para la deteccion de anomalias, al ser comparado con los metodos Laplacian Anomaly Detection (LAD) y Tensorsplat.

Se emplean 4 modelos de generacion de redes, de los cuales se simula una serie temporal de 100 redes, con 100 nodos. En todas las simulaciones se introduce una anomalia en el tiempo $t=50$ y se consideran diferentes variaciones de la probabilidad $p$ de conexion entre nodos.

--------

1. Redes de Erdős-Rényi con una probabilidad $p=0,05$ constante de conexión entre nodos, en $t=50$ se tiene $p=p_*$ con $p_* \in \{0.1, 0.15, 0.2, 0.25\}$

2. Redes de Erdős-Rényi Dinámicas, donde la probabilidad
de conexión entre los nodos aumenta linealmente a lo largo del tiempo, en $t=50$ $p = 0.2727 + p_*$, con $p_* \in \{0.05, 0.1, 0.15, 0.2\}$

------

3. Redes de Barabási-Albert que siguen un modelo de conexión preferencial, donde algunos nodos tienen una probabilidad mayor de formar nuevas conexiones. 

4. Redes de Watts-Strogatz con propiedades de mundo pequeño, caracterizadas por altos niveles de agrupamiento y cortas distancias promedio entre nodos, $p$ aumenta de $0.05$ a $0.3$, pero en el tiempo $t=50$ $p=0.1737 + p_*$ con $p_* \in \{0.05, 0.1, 0.15, 0.2\}$

# 

<div class="grid-container">
  
  <div class="grid-item">
  
  <img src="RED 1.png" alt="Imagen 1">
  
  </div>
  
  <div class="grid-item">
    
  <img src="RED 2.png">
    
  </div>
  
  <div class="grid-item">
  
  <img src="RED 3.png">
  
  </div>
  
  <div class="grid-item">
    
  <img src="RED 4.png">
  
  </div>
  
</div>
<style>
.grid-container {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    grid-gap: 10px;
}

.grid-item img {
    max-width: 100%;
    height: auto;
}
</style>

-------------------------------------------------------------

### Ejercicio datos reales

Redes de Co-votación del Senado de EE.UU: Incluye las redes de co-votación en el Senado de EE.UU. desde el 40° hasta el 113°
Congreso, donde los nodos representan a los senadores y las aristas indican co-votaciones entre
ellos.

---------------------------------------------------------------


<p align="center">

<img src="congreso USA.png" width="950"/>

</p>

------

<p align="center">

<img src="congreso anomalias.png" width="1000"/>

</p>


# Gracias
