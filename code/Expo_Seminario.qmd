---
title: "Anomaly detection in dynamic networks"
author: "Andreina Alamo, Zaith Moreno, Diego Useche"
subtitle: "Seminario I 2024-I"
institute: "Universidad Nacional de Colombia"
format:
  revealjs: 
    center: true
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: "logoUN3.PNG"
    #footer: Universidad Nacional de Colombia
editor: visual
# toc: true
toc-title: Contenido
progress: true
---




## Objetivos

- Generar un método que permita detectar anomalías en cualquier secuencia de redes dinámicas
- Generalizar la modelacion de series de tiempo basado en características para la detección de
anomalías en redes dinámicas
- Medir el rendimiento de **oddnet** comparado con otros metodos (LAD y Tensorsplat)


## Redes

![Visualización de redes (gráfos)](Red1.png){fig-align="center"}

$\bullet$ Red $\bullet$ Grafo $\bullet$ Objetos (vértices o nodos) $\bullet$ Conexiones (enlaces o aristas)$\bullet$ Interacciones (propiedades a nivel global)$\bullet$

## Ejemplos de redes

::: panel-tabset
### Estructuras cerebrales

![](brain.png){width="300" height="300"}

### Redes de trenes

![](train.png){width="250" height="250"}

### Redes eléctricas

![](electric.png){width="250" height="250"}

### Redes Sociales

![](social.png){width="300" height="300"}
:::

## Redes dinámicas

![Redes dinámicas (componente temporal)](Red2.png)

## ¿Por qué es importante la detección de anomalías? {.smaller}

-   Accidentes, eventos sospechosos, actividad inusual que merece **investigación adicional**.
-   Los estudios sobre la detección de anomalías en Redes Dinámicas son **limitados**.
-   Existen estudios sobre anomalías en nodos y aristas, o en subgrafos de estructuras de interés, pero no sobre los **puntos en el tiempo** donde se producen estas anomalías.
-   Akoglu (2015) categorizó las técnicas de detección de anomalías en Redes Dinámicas en cuatro grupos: Características, Descomposición, Agrupamiento y Ventanas.

## ***oddnet***

> *Series de tiempo*: tratamiento de patrones estacionales complejos que la similaridad no alcanza a capturar

> *Análisis de redes*: Examinar las caracteristicas (Features) de las redes en el tiempo

> *Reducción de dimensionalidad*:recolectar la mayor cantidad de información de las caracteristicas en en plano

## Algoritmo ***oddnet***

![](algoritmo.PNG)


<!-- Termina Zaith -->

<!-- Empieza Andreina -->


## Anomalía en redes dinámicas {.smaller}

Considere una secuencia de redes temporales $\left\{\mathcal{G}_t\right\}_{t=1}^T$ donde cada red es un grafo $\mathcal{G}_t=\left(\mathcal{V}_t , \mathcal{E}_t\right)$, con $\mathcal{V}_t$ denotando los vértices y $\mathcal{E}_t$ las aristas Estamos interesados en el proceso general o a largo plazo de generación de redes. Una anomalía se define como un punto con baja probabilidad condicional


$$
\begin{aligned}
p_{t \mid t-1}=\mathcal{P}\left(\mathcal{G}_t \mid \mathcal{G}_1, \ldots, \mathcal{G}_{t-1}\right). 
\end{aligned}
$$ Es decir, un grafo $\mathcal{G}_t$ es anómalo si su probabilidad de ocurrencia es baja dada la secuencia de gráficos que lo preceden.

## Mapeo del espacio de gráficos al espacio de características

Sea $f$ una función de cálculo de características tal que $f: \mathscr{G} \rightarrow \mathbb{R}^n$, donde $\mathscr{G}$ denota el espacio de todas las redes, y sea $x_t$ la imagen de $\mathcal{G}_t$ bajo $f$. Así, $x_t$ es un vector de $n$ características correspondientes a $\mathcal{G}_t:$

$$
x_t=f\left(\mathcal{G}_t\right),
$$

donde $x_t \in \mathbb{R}^n$. Sea $\mathcal{F}$ el codominio de $f$, al cual llamaremos espacio de características.

## 

Este espacio de características $\mathcal{F}$ debe retener aspectos de la distribución del espacio de grafos $\mathscr{G}$. Así, la probabilidad condicional definida para la detección de anomalías se puede estimar como sigue:

$$
\tilde{p}_{t \mid t-1}=\mathcal{P}\left(x_t \mid x_1, \ldots, x_{t-1}\right).
$$

donde $x_t \in \mathbb{R}^n$.

## Definición 2.1

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Acuerdo Total para un conjunto de grafos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si

$$
p_{t \mid t-1}=\tilde{p}_{t \mid t-1} \quad \text { para todo } t \in\{1, \ldots, T\} .
$$

La Condición de Acuerdo Total es la forma más estricta de acuerdo entre los dos espacios $\mathscr{G}$ y $\mathcal{F}$. A continuación, se define una versión más flexible.

## Definición 2.2

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Acuerdo Aproximado con parámetro $\epsilon$, o se dice que es $\epsilon$-aproximada para un conjunto de gráficos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si

$$
\left|p_{t \mid t-1}-\tilde{p}_{t \mid t-1}\right| \leq \epsilon \quad \text { para todo } t \in\{1, \ldots, T\} ，
$$

donde $\epsilon>0$ y es pequeño.

## Definición 2.3

Una función $f: \mathscr{G} \rightarrow \mathbb{R}^n$ satisface la Condición de Preservación de Anomalías con parámetro $\epsilon$, o se dice que es $\epsilon$-preservadora de anomalías para un conjunto de gráficos $\left\{\mathcal{G}_t\right\}_{t=1}^T$, si 

$$
p_{t \mid t-1} \leq \epsilon_1 \Longleftrightarrow \tilde{p}_{t \mid t-1} \leq \epsilon_2
$$

donde tanto $\epsilon_1$ como $\epsilon_2$ son pequeños.

## Lema 2.1

Las condiciones de acuerdo están anidadas, es decir, Condición de Acuerdo Total $\Rightarrow$ Condición de Acuerdo Aproximado, Condición de Acuerdo Aproximado $(\epsilon / 2) \Rightarrow$ Condición de Preservación de Anomalías $(\epsilon)$.

## Ejemplo

<p align="center">

<img src="ejemplo1.png" width="1000"/>

</p>

<!-- Termina Andreina -->


## Características{.smaller}
::: panel-tabset
## 1-5
1.  Distribución de triángulos:# de triángulos conectados a c/nodo
2.  Grado: \# de aristas conectado a cada nodo
3.  Densidad: \# de aristas observadas/total posibles aristas
4.  Total de aristas en $\mathcal{G}_t$
5.  Transitividad (*amigos de amigos*):Proporción de nodos cuyos nodos adyacentes también están conectados

## 6-10{.smaller}

6.  Asortatividad: Medición de la homofilia [^1] del grafo, basándose en las etiquetas de los nodos
7.  Distancia media: calcula la media de todos los caminos entre diferentes nodos
8.  Diámetro: Distancia más grande del grafo [^2]
9.  Proporción de nodos no conectados

10. Centralidad: Mide qué tan "cerca" está un nodo a otros nodos 


[^1]: Nodos similares tienen a conectarse entre sí

[^2]: Distancia es la caminata más corta entre dos nodos


<!-- Termina Zaith -->
<!-- Empieza Andreina -->

## 11-13

11. La conectividad de vértices: indica el número mínimo de vértices/nodos que hay que eliminar para que el grafo no esté fuertemente conectado.
12. La eficiencia global: la media de las distancias inversas por pares entre todos los pares de nodos.
13. Se extraen dos características de los componentes conectados de la red. De la distribución del número de nodos en cada componente conectado se utiliza el  cuantil $99^{th }$

## 14-16
14. También se incluye el número de componentes conectados.
15. La centralidad de proximidad de un vértice mide lo cerca que está ese vértice de otros vértices del grafo. Se define como la inversa de la suma de las distancias a todos los vértices. Se incluye la proporción de vértices con proximidad $\geq 0,8$ en el vector de características. 

16. La centralidad entre nodos mide en qué medida un nodo conecta a otros nodos al ser un intermediario. Se define como los caminos más cortos que pasan por un nodo.

## 17-18
17. Se calcula el PageRank de todos los vértices y se toma el cuantil $99^ {th }$.
18. Las puntuaciones hub de los vértices se definen como el vector propio principal de $A A^T$ donde $A$ denota la matriz de adyacencia. Se utliza el valor propio principal correspondiente a las puntuaciones hub como una característica.

## 19-20
19. Las puntuaciones de autoridad de los vértices son el vector propio principal de $A^T A$. Se Incluye el valor propio principal correspondiente a las puntuaciones de autoridad como una característica.

20. El núcleo $k$ de un grafo: subgrafo máximo con un grado mínimo de al menos $k$. Es decir, cada vértice de un núcleo $k$ tiene un grado mayor que $k$. Se calcula  **coreness** para todos los vértices y se incluye el cuantil $99^{th }$.

:::


## Proceso de generación de red {.smaller}

El proceso que genera la red puede crear dependencias temporales dentro del espacio de características. Por ejemplo, si el número de conexiones en una red aumenta con el tiempo, una disminución repentina en el número de conexiones en un punto específico del tiempo se consideraría una anomalía. Es crucial capturar este comportamiento. Simplemente identificar anomalías en el espacio de características no nos permitiría señalar esa anomalía en particular, como se ilustra en la Figura 4.

------------------------------------------------------------------------

<p align="center">

<img src="figure_4.png" width="1000"/>

</p>

------------------------------------------------------------------------

Para modelar el comportamiento temporal, utilizamos métodos para pronósticar series de tiempo sobre las características de la red.

Sea $x_{\cdot, i}=\left\{x_{t, i}\right\}_{t=1}^T$ el conjunto de series temporales univariadas de la $i$-ésima característica.

-   Se ajustan modelos ARIMA a cada serie temporal de características $x_{\cdot, i}$ para $i \in \{1, \ldots, n\}$.

-   Si el modelo ha capturado adecuadamente la dependencia temporal, entonces $e_{t, i} \sim \mathcal{NID}\left(0, \sigma^2\right)$ y los residuos no mostrarán correlación temporal.

## Definición 2.4.

Los modelos ARIMA aproximan el proceso generador de la red con el parámetro $\delta$, si

$$
\tilde{p}_{t \mid t-1} \geq \delta \Longleftrightarrow \left\| \boldsymbol{e}_t \right\| \leq c(\delta),
$$ para valores pequeños de $\delta$. Esto asegura que los modelos ARIMA capturan los patrones generales, incluyendo la tendencia y la estacionalidad en el espacio de características, al mapear puntos de alta densidad en la distribución condicional $f\left(\mathcal{G}_t\right) \mid \mathcal{G}_1, \ldots, \mathcal{G}_{t-1}$ a residuos pequeños.

--------------

Si una función $f$ satisface la Condición de Preservación de Anomalías con parámetro $\epsilon$, y si los modelos ARIMA aproximan el proceso generador de la red con parámetro $\delta$ con $\delta \geq \epsilon$, entonces un grafo anómalo $\mathcal{G}_t$ da lugar a una anomalía en el espacio de residuos del ARIMA, es decir, existe un valor pequeño $\xi$ tal que $\mathcal{P}\left(\boldsymbol{e}_t\right) \leq \xi$, donde $\xi=\xi(\delta)$ y $\boldsymbol{e}_t$ es el residuo correspondiente al grafo $\mathcal{G}_t$.

------------------------------------------------------------------------

Así, queda demostrado que los grafos anómalos quedan representados por residuales de valores grandes resultantes del ajuste del modelo ARIMA.

------------------------------------------------------------------------

<p align="center">

<img src="figure_5.png" width="1000"/>

</p>

------------------------------------------------------------------------


## Reduccion de dimensionalidad y deteccion de anomalias

Identificar anomalías en dimensiones altas supone una dificultad, dado que los puntos pueden estar muy lejos unos de otros y muchos puntos residen en regiones de baja densidad. Además, se pueden correlacionar errores de diferentes características.

**¿Como? -\>** Reduccion de dos dimensiones, dobin, ó PCA robusto.

## 

Para nuestros escenarios de red, una PCA robusta proporcionó un mejor rendimiento en comparación con dobin, posiblemente porque dobin no manejó las correlaciones tan bien como un PCA robusto

El PCA usado utiliza una estimacion robusta de la varianza dada por la desviacion absoluta mediana al cuadrado

$$ \operatorname{MAD}\left(z_1, \ldots, z_n\right)=1.48 \operatorname{med}_j\left|z_j-\operatorname{med}_i z_i\right| $$

<!-- Termina Diego -->
<!-- Empieza Andreina -->

## Deteccion de anomalias

El ultimo paso es la detección de anomalias en el espacio reducido a dos dimensiones, esto se realiza mediante el algortimo **lookup**.

Los métodos de detección de anomalías que utilizan estimaciones kernel de la densidad generalmente emplean un parámetro definido por el usuario para determinar el ancho de banda. Lookout utiliza análisis de datos topológicos para construir un ancho de banda adecuado para la detección de anomalías sin necesidad de ninguna entrada del usuario.

## Algoritmo Lookup{.smaller}

1. Se escalan las variables de 0 a 1.
2. Se modela la nube de puntos utilizando el complejo de Vietoris–Rips, el cual forma nexos entre las observaciones. El ancho de banda estará dado por la máxima diferencia de las distancias entre nacimientos de nexos.
3. Se estima la densidad kernel clásica a los datos con este ancho de banda y sus valores se denotan $y_i$, y también la versión _leave one out_ que se denotan $y_{-i}$.
4. Utilizando EVT (teoría de valores extremos) se ajusta una distribución generalizada de pareto (GPD) a $\left\{-\log \left(y_i\right)\right\}_{i=1}^N$ y se estiman sus parámetros $\mu$, $\sigma$ y $\xi$.
5. Se calcula $P\left(-\log \left(y_{-i}\right) \mid \mu, \sigma, \xi\right)$ y si es menor a un $\alpha$ tan pequeño como se desee, la observacion $i$ es una anomalía.
 
<!-- Termina Andreina -->
<!-- Empieza Diego -->


## Proceso general del algoritmo


El proceso general del algoritmo **oddnet** se puede describir con el siguiente diagrama:

<p align="center">

<img src="proceso general.png" width="1000"/>

</p>


## Resultados

::: panel-tabset
## Exp 1

<img src="RED 1.png" alt="Imagen 1"/>


## Exp 2

<img src="RED 2.png"/>

## Exp 3

<img src="RED 3.png"/>

## Exp 4

<img src="RED 4.png"/>
:::


--------

1. Redes de Erdős-Rényi con una probabilidad $p=0,05$ constante de conexión entre nodos, en $t=50$ se tiene $p=p_*$ con $p_* \in \{0.1, 0.15, 0.2, 0.25\}$

2. Redes de Erdős-Rényi Dinámicas, donde la probabilidad
de conexión entre los nodos aumenta linealmente a lo largo del tiempo, en $t=50$ $p = 0.2727 + p_*$, con $p_* \in \{0.05, 0.1, 0.15, 0.2\}$

------

3. Redes de Barabási-Albert que siguen un modelo de conexión preferencial, donde algunos nodos tienen una probabilidad mayor de formar nuevas conexiones. 

4. Redes de Watts-Strogatz con propiedades de mundo pequeño, caracterizadas por altos niveles de agrupamiento y cortas distancias promedio entre nodos, $p$ aumenta de $0.05$ a $0.3$, pero en el tiempo $t=50$ $p=0.1737 + p_*$ con $p_* \in \{0.05, 0.1, 0.15, 0.2\}$

```{=html}
<style>
.grid-container {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    grid-gap: 10px;
}

.grid-item img {
    max-width: 100%;
    height: auto;
}
</style>
```

------------------------------------------------------------------------

### Ejercicio datos reales

Redes de Co-votación del Senado de EE.UU: Incluye las redes de co-votación en el Senado de EE.UU. desde el 40° hasta el 113° Congreso, donde los nodos representan a los senadores y las aristas indican co-votaciones entre ellos.

------------------------------------------------------------------------

<p align="center">

<img src="congreso USA.png" width="950"/>

</p>

------------------------------------------------------------------------

<p align="center">

<img src="congreso anomalias.png" width="1000"/>

</p>


<!-- Termina Diego -->

## Conclusiones y limitaciones
::: panel-tabset

## 1

**Oddnet** obtiene mejores resultados que LAD y Tensorsplat.
-   El método funciona bien con redes generadas por el modelo Erdos-Renyi, de alguna manera, el modelo más sencillo de generación aleatoria de redes; seria interesante probar la efectividad del método **oddnet** con otros modelos como modelos de Grafos Aleatorios Generalizados, modelos de Grafos Aleatorios Exponenciales, y modelos de Bloques Estocásticos

## 2

Falta la extensión de \textit{oddnet} para encontrar anomalías en subredes de grandes bases de datos

## 3  

La reducción de la dimensionalidad en en el espacio residual se usa para traer información de la varianza a dos dimensiones, si bien es cierto esto tiene gran potencial en la interpretabilidad, podría ser insuficiente en la recolección de la información en su totalidad

## 4  

El modelo ARIMA podría no siempre ser la mejor opción para modelar una serie de tiempo.
:::

## Bibliografía 

- Akoglu, L., Tong, H. & Koutra, D. (2015), ‘Graph based anomaly detection and description: A survey’, *Data Mining and Knowledge Discovery* 29(3), 626–688.
- Albert, R. & Barabasi, A.-L. (2002), ‘Statistical mechanics of complex networks’, *Reviews of modern physics* 74(1), 47.
- Almquist, Z. W. & Butts, C. T. (2013), ‘Dynamic network logistic regression: A logistic choice analysis of inter- and intra-group blog citation dynamics in the 2004 US presidential election’, *Political Analysis* 21(4), 430–448.
- Barabasi, A.-L. & Albert, R. (1999), ‘Emergence of scaling in random networks’, *Science* 286(5439), 509–512.

# ¡Gracias!


